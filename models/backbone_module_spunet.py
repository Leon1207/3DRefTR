"""
SparseUNet Driven by SpConv (recommend)

Author: Xiaoyang Wu (xiaoyang.wu.cs@gmail.com)
Please cite our work if the code is helpful to you.
"""

from functools import partial
from collections import OrderedDict

import torch
import torch.nn as nn
import random
import math

try:
    import spconv.pytorch as spconv
except ImportError:
    import warnings
    warnings.warn(
        'Please follow `README.md` to install spconv2.`')


def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor


def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    # type: (Tensor, float, float, float, float) -> Tensor
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)


class BasicBlock(spconv.SparseModule):
    expansion = 1

    def __init__(self,
                 in_channels,
                 embed_channels,
                 stride=1,
                 norm_fn=None,
                 indice_key=None,
                 bias=False,
                 ):
        super().__init__()

        assert norm_fn is not None

        if in_channels == embed_channels:
            self.proj = spconv.SparseSequential(
                nn.Identity()
            )
        else:
            self.proj = spconv.SparseSequential(
                spconv.SubMConv3d(in_channels, embed_channels, kernel_size=1, bias=False),
                norm_fn(embed_channels)
            )

        self.conv1 = spconv.SubMConv3d(
            in_channels, embed_channels, kernel_size=3, stride=stride, padding=1, bias=bias, indice_key=indice_key
        )
        self.bn1 = norm_fn(embed_channels)
        self.relu = nn.ReLU()
        self.conv2 = spconv.SubMConv3d(
            embed_channels, embed_channels, kernel_size=3, stride=stride, padding=1, bias=bias, indice_key=indice_key
        )
        self.bn2 = norm_fn(embed_channels)
        self.stride = stride

    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = out.replace_feature(self.bn1(out.features))
        out = out.replace_feature(self.relu(out.features))

        out = self.conv2(out)
        out = out.replace_feature(self.bn2(out.features))

        out = out.replace_feature(out.features + self.proj(residual).features)
        out = out.replace_feature(self.relu(out.features))

        return out


class SpUNetBase(nn.Module):
    def __init__(self,
                 in_channels=3,
                 out_channels=288,
                 base_channels=32,
                 channels=(32, 64, 128, 256, 256, 128, 96, 96),
                 layers=(2, 3, 4, 6, 2, 2, 2, 2)):
        super().__init__()
        assert len(layers) % 2 == 0
        assert len(layers) == len(channels)
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.base_channels = base_channels
        self.channels = channels
        self.layers = layers
        self.num_stages = len(layers) // 2
        self.scale = 0.02

        norm_fn = partial(nn.BatchNorm1d, eps=1e-3, momentum=0.01)
        block = BasicBlock

        self.conv_input = spconv.SparseSequential(
            spconv.SubMConv3d(in_channels, base_channels, kernel_size=5, padding=1, bias=False, indice_key='stem'),
            norm_fn(base_channels),
            nn.ReLU(),
        )

        enc_channels = base_channels
        dec_channels = channels[-1]
        self.down = nn.ModuleList()
        self.up = nn.ModuleList()
        self.enc = nn.ModuleList()
        self.dec = nn.ModuleList()

        for s in range(self.num_stages):
            # encode num_stages
            self.down.append(spconv.SparseSequential(
                spconv.SparseConv3d(enc_channels, channels[s], kernel_size=2, stride=2, bias=False,
                                    indice_key=f"spconv{s + 1}"),
                norm_fn(channels[s]),
                nn.ReLU()
            ))
            self.enc.append(spconv.SparseSequential(OrderedDict([
                # (f"block{i}", block(enc_channels, channels[s], norm_fn=norm_fn, indice_key=f"subm{s + 1}"))
                # if i == 0 else
                (f"block{i}", block(channels[s], channels[s], norm_fn=norm_fn, indice_key=f"subm{s + 1}"))
                for i in range(layers[s])
            ])))

            # decode num_stages
            self.up.append(spconv.SparseSequential(
                spconv.SparseInverseConv3d(channels[len(channels) - s - 2], dec_channels,
                                           kernel_size=2, bias=False, indice_key=f"spconv{s + 1}"),
                norm_fn(dec_channels),
                nn.ReLU()
            ))
            self.dec.append(spconv.SparseSequential(OrderedDict([
                (f"block{i}", block(dec_channels + enc_channels, dec_channels, norm_fn=norm_fn, indice_key=f"subm{s}"))
                if i == 0 else
                (f"block{i}", block(dec_channels, dec_channels, norm_fn=norm_fn, indice_key=f"subm{s}"))
                for i in range(layers[len(channels) - s - 1])
            ])))
            enc_channels = channels[s]
            dec_channels = channels[len(channels) - s - 2]

        self.final = spconv.SubMConv3d(channels[-3], out_channels, kernel_size=1, padding=1, bias=True) \
            if out_channels > 0 else spconv.Identity()
        self.apply(self._init_weights)

    @staticmethod
    def _init_weights(m):
        if isinstance(m, nn.Linear):
            trunc_normal_(m.weight, std=.02)
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, spconv.SubMConv3d):
            trunc_normal_(m.weight, std=.02)
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.BatchNorm1d):
            nn.init.constant_(m.bias, 0)
            nn.init.constant_(m.weight, 1.0)

    def _break_up_pc(self, pc):
        xyz = pc[..., 0:3].contiguous()
        features = (
            pc[..., 3:].transpose(1, 2).contiguous()
            if pc.size(-1) > 3 else None
        )

        return xyz, features

    def forward(self, pointcloud, end_points=None):

        if not end_points:
            end_points = {}

        coord, feat = self._break_up_pc(pointcloud)       # ([B, 50000, 3]), [B, 3, 50000])
        B, N = coord.shape[0], coord.shape[1]
        coord = coord.reshape(B * N, 3)
        feat = feat.permute(0, 2, 1).reshape(B * N, 3)
        batch = torch.arange(0, B).unsqueeze(-1).expand(B, N).reshape(B * N).cuda()

        discrete_coord = torch.floor(coord / self.scale)
        discrete_coord -= discrete_coord.min(0).values

        sparse_shape = torch.add(torch.max(discrete_coord, dim=0).values, 1).tolist()  # [314.0, 423.0, 131.0]
        x = spconv.SparseConvTensor(
            features=feat,
            indices=torch.cat([batch.unsqueeze(-1).int(), discrete_coord.int()], dim=1).contiguous(),
            spatial_shape=sparse_shape,
            batch_size=batch[-1].tolist() + 1
        )
        x = self.conv_input(x)
        skips = [x]
        # enc forward
        for s in range(self.num_stages):
            x = self.down[s](x)  # 200000, 128156, 54052, 14632, 3692, 778
            x = self.enc[s](x)
            skips.append(x)
        x = skips.pop(-1)

        # dec forward, only using the first twp stages
        for s in reversed(range(self.num_stages)):
            x = self.up[s](x)  # 3692, 14632
            skip = skips.pop(-1)
            x = x.replace_feature(torch.cat((x.features, skip.features), dim=1))
            x = self.dec[s](x)
            if s == 2:
                break

        x = self.final(x)  # [B * N, 288]

        end_points['fp2_xyz'] = []
        end_points['fp2_features'] = []
        for i in range(B):
            idx = x.indices[:, 0] == i  # fetch each batch point cloud
            f = x.features[idx].permute(1, 0)  # [288, 3658]
            c = x.indices[idx][:, 1:].float() * self.scale  # [3658, 3]
            # random sampling 1024 points
            N, sample_num = f.shape[-1], 1024
            if N < sample_num:
                down_f = f.repeat(1, int(sample_num / N) + 1)[:, :sample_num]
                down_c = c.repeat(int(sample_num / N) + 1, 1)[:sample_num, :]
            else:
                index = torch.LongTensor(random.sample(range(N), sample_num)).cuda()
                down_c = torch.index_select(c, 0, index)
                down_f = torch.index_select(f, 1, index)

            end_points['fp2_xyz'].append(down_c)
            end_points['fp2_features'].append(down_f)

        end_points['fp2_xyz'] = torch.stack(end_points['fp2_xyz'], dim=0)  # [B, 1024, 3]
        end_points['fp2_features'] = torch.stack(end_points['fp2_features'], dim=0)  # [B, 288, 1024]
        
        print(end_points['fp2_xyz'], end_points['fp2_features'])

        return end_points